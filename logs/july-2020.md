# July 2020

## July 31, 2020

- \[5:55-6:15\]: arXiv and web browsing on iPad (looking at winner of Citadel datathon).
- \[6:15-7:56\]: Picked up on the TRW approximation. Focused on role of convexity/concavity and Jensen's inequality. Basically, it all boils down to showing that a certain application of Jensen's inequality is tight. Typically, this happens when the underlying r.v. is well-concentrated. I want to prove that the TRW free energy is at most the true free energy plus the entropy of the tree distribution. It seems to hold when the graph is tree or when it is completed graph (maybe). I looked into some of the ML/empirical studies to see what happens for intermediate cases. It seems like for graphs with few loops, one can actually get dimension independent error for log partition function approximation. Decomposing a Ising model into mixture of simpler distributions is not the same thing as decomposing the interaction matrix (graph) into a mixture of tree-interaction matrices.
- \[1:38-3:45\]: Attended discrete analysis seminar of Nikhil Srivastava. Today's talk was by Theo Mckenzie on upper bounding eigenvalue multiplicity of graphs. Just wanted to attend to see what it was like. I was pretty bored, but followed most of the talk. Stopped paying attention after 45 minutes and was internet browsing. Around 2:30 I started playing around with Bethe free energy again and realized a connection between the rounding idea of Jeff. In some special cases, Bethe free energy lower bounds true free energy. We can get the other direction by trying to round any valid distribution to a tree-like distribution. The idea is that conditioning is like deleting vertices. So, I want to delete a sublinear number of vertices of my graph such that the resulting graph doesn't really have any short cycles. This type of technical result was exactly what Theo mentioned in his talk. It actually seems pretty promising, but I need to see if quantitative bounds tradeoff to give something meaningful.
- \[3:45-5:40\]: Met with Sidhanth. Talked about the usual open problems. Started thinking about the coupling problem that Prasad suggested; I think there might be some interesting connections to identifiability here. He also suggested lower bounds for local statistics hierarchy as a good open problem. Seems like they like community detection a lot. We agreed to try to find some of the big picture problems to work on, rather than just hard technical problems or rigorizing physics predictions. Felt very tired afterwards. Starting to get the impression that there isn't much the "top" students can do that I can't do myself. Somehow, I feel they are just a bit more savvy and efficient in actually producing papers. I suspect doesn't have too much to do with how much they work, but rather what they actually work on. Maybe they just keep talking a lot more.

## July 30, 2020
Also, every morning, I check arXiv while drinking hot water aftter shower.

- \[7:30-7:38\]: Time wasting on PD Soros.
- \[7:38-8:32\]: Wrote down this log and for yesterday. Thought about Boaz's idea and realized it doesn't give as the optimal rate in subexponential time; we can only match the suboptimal rate in that time. But, it is at least a good starting point. Need to meet with Fred.
- \[8:32-9:34\]: Read about BP on trees in MM Chapter 14. I think I have a better understanding of how tree-graphical models factorize and where the Bethe free energy expressions come from.
- \[1:15-3:15\]: Tried fiddling around with Bethe free energy to see if some kind of decomposition into mixture of tree-structured distributions would allow us to bound error of Bethe approximation. Didn't really make any progress. Started reading some Wainwright-type of papers on convexifying Bethe free energy. In particular, I sort of understand tree-reweighted Bethe approximation.
- \[3:15-3:30\]: Went outside but kept thinking about TRW approximation

## July 29, 2020

- \[5:45-7:13\]: Worked on heavy tailed covariance estimation project. Here is the summary I sent to Fred:  

> I continued to think about what we discussed last time and have some ideas. First, we can show that if X is a spectral center (or SoS relaxation version) then X is a combinatorial center - this proof is easy and is very similar to before. Second, we can show that if X is a (\alpha \lambda)-combinatorial center, then X is is (\lambda)-spectral center (SoS version), where \alpha (a number less than one) is the approximation factor we lose in the rounding of the degree 4 pseudodistribution to a singe unit vector.  
If we write A = (Z_i - X) \otimes (Z_i - X), then we want to approximate the injective tensor norm of this tensor, up to approximation factor \alpha.
It can be shown that if this is possible, the final radius achieved by the estimator will be (1 / \sqrt{alpha}) times the optimal radius. Hence, we want to ensure alpha >= 1/\sqrt{d}, which would allow us to at least match the Hopkins et al. result.
So, it all reduces to the above problem; let me tell you what is currently known about approximately maximizing degree 4 polynomials over the unit sphere.
First, Barak-Kelner-Steurer ( https://www.dsteurer.org/paper/sosround.pdf) give a QPTAS (so alpha = 1- epsilon) in the case that the entries of A are non-negative. This would give us the optimal statistical radius for covariance estimation in quasi-polynomial time.
Second, Bhattiprolu et al. (https://arxiv.org/abs/1611.05998,  https://arxiv.org/abs/1605.00903) show that one can achieve alpha >= 1/sqrt{d} in polynomial time if A has non-negative entries or if A is random (with say +/- 1 entries). This would allow us to match Hopkins et al. result in polynomial time.
Unfortunately, there are three issues we need to resolve.
1. Clearly, our A does not have nonnegative entries. However, it does have some structure, so maybe there is hope of recovering these results. Our A actually is random, but not from a nice ensemble like what is studied in Bhattiprolu et al. I am currently trying to understand the proofs of these results to see if they can be made to work for our case.
2. These approximation bounds actually have a dependence on operator norm of A (viewed as d^2 x d^2) matrix. In particular, the approximating gets worse when this norm is small. Heuristically, let me guess that norm(A) = norm(Z_i - X)^2. It could be that  norm(Z_i - X) ~ 1/sqrt{n}, so norm(A) ~ 1/n, which is really bad. We should actually check this issue first, because it might just make this whole approach impossible.
3. The above polynomial time algorithtms of Bhattiprolu use SoS. Since we care about the degree 4 case only and our A can actually be specified by (Z_i - X) (which has d^2 entries), there is some hope that we can get a fast spectral algorithm from their analysis

- \[1:55-3\]: Met with Jeff. We narrowed down to three concrete tasks. First, can we prove a better correlation rounding result for expanders or low-threshold rank graphs? Second, why is there a gap between when we can approximately count solutions to random 3SAT formulas (see Galanis et al.) and when we can actually find a solution? Can we close this gap? Can we extend their counting algorithm to other problems? For example, what about random 2SAT? Third, can we give provable bounds on a convexified Bethe free energy? There are some candidate surrogates for Bethe free energy in the ML literature, but not much provable guarantees. Or, can we just prove that BP just converges to the Bethe free energy (i.e. reverse the order of limits in the Coja-Oghlan paper)?
- \[3-3:50\]: Met with Prasad. Was feeling anxious all day, but for no reason. Talked about fall visit plans. Then we talked about various research directions related to SoS and statistical physics. Do plan to follow up and keep talking. Felt a huge wave of relief after this and lighthearted this rest of the day.
- \[4:05-4:30\]: Met with Boaz. Explained to him our degree-4 polynomial optimization problem. Initially, I explained it incorrectly, but reformulated problem so it made sense. He suggested some subexponential time algorithm involving brute-force + simultaneous eigenvalue problem; seems promising. Will think about it and try to meet with Fred.
- \[4:50-5:15\]: Attended Boaz group meeting.


## July 28, 2020

- \[6:45-9:45\]: Dug through [JKR] and references therein to find open problems. Decided to stick to the convex programming approach, separate from random CSPs. Identified two open problems and did some initial checks to make sure there is hope for them (i.e. that they are not asking for something that is impossible or contradictory to what we already know). First is getting a better free energy approximation for sparse random graphs by getting a better correlation rounding result for expanders/low threshold rank graphs. There is some evidence this may be possible in papers by Makarychev and Manurangsi-Raghavendra. Second is getting provable bounds on  error of Bethe approximation for Ising models on sparse graphs. This doesn't violate lower bounds in [JKR] as long as results are restricted to high temperature. Wasted some time trying to understand the horrendous Dembo-Montanari survey. Skipped to MM book chapters 14.
- \[1:35-2:35\]: Woke up from a 30 minute nap on the deck and jumped into Ankur Moitra's Simons Institute lecture on Barak-Kelner-Steurer algorithm for approximating injective tensor norm. Felt like it was a very good presentation and I understood everything. Realized that we can't directly apply it to our problem because some of the entries of our tensor may be negative. Also, need to analyze the norm of our tensor to check for the correct scaling.
- \[2:35-2:50\]: Wasted a few minutes browsing random papers, made my back stiff again, so had to wait > 30 minutes before going outside.
